---
title: "Report - TP2"
author: "Jose Munoz Angulo, Vivien Marcault, Baptiste Rigondaud"
date: "February 26, 2018"
output: html_document
---

## Question 1

The map is produced with this code:

```{r}
NAm2 = read.table("NAm2.txt", header=TRUE)

names=unique(NAm2$Pop)
npop=length(names)
coord=unique(NAm2[,c("Pop","long","lat")]) #coordinates for each pop
colPalette=rep(c("black","red","cyan","orange","brown","blue","pink","purple","darkgreen"),3)
pch=rep(c(16,15,25),each=9)
plot(coord[,c("long","lat")],pch=pch,col=colPalette,asp=1)
# asp allows to have the correct ratio between  axis  longitude and latitude
# Then the map is not deformed  
legend("bottomleft",legend=names,col=colPalette,lty=-1,pch=pch,cex=.75,ncol=2,lwd=2)
library(maps);map("world",add=T)
```

The map is created by extracting all unique indigenous population along with its latitude and longitude. By the means of the maps library we draw the map with the populations in its location, using 9 different colors and three different symbols.

## Question 2

The linear regression can be computed like this:

```{r, eval=FALSE}
NAaux = NAm2[,-c(1:7)]
y <- lm(long ~ ., data = NAaux)
summary(y)
```

However R can not invert the matrix to solve te linear regression problem, because of the size of the matrix. Thus, it explains why the linear regression summary is full of Not A Number. In order to have a correct model, we could take a subset of the predictors using this command:

```{r, eval=FALSE}
prcomp(rank=2, NAm2[,-c(1:8)])
```

In the following questions, we are going to use PCA.

## Question 3

### a)
This method consist into diagonalizing the covariance matrix in order to find its maximum eigenvalues. These values correspond to the components of maximum variance. Therefore if we make a projection of the data on the factorspace generated by the corresponding eigenvectors, we preserve the maximum information that we can have from the original data in this dimension.

### b)
The PCA on the genetic data can be computed like this:
```{r}
pcaNAm2 = prcomp(NAm2[,-c(1:8)], scale=TRUE)
```
We use the scale parameter in order to normalize the variances of each component, because each values for each component can be scaled differently, causing variances to be very different.

### c)
```{r}
caxes=c(1,2)
plot(pcaNAm2$x[,caxes],col="white")
for (i in 1:npop) {
  lines(pcaNAm2$x[which(NAm2[,3]==names[i]),caxes],
        type="p",col=colPalette[i],pch=pch[i])
}
legend("bottomleft",legend=names,col=colPalette,lty=-
         1,pch=pch,cex=.75,ncol=3,lwd=2)
```

The graph maps the weight of each genetic samples regarding the two first components of the PCA. We can see that these two first components gathers all the members of a population, but gathers also all the population around the same area.
The 5th and th 6th axes separate more the populations (Pima, Karitiana) compared to the two first axes.

### d)
In order to have the percentages, we use the command:
```{r}
prop = summary(pcaNAm2)$importance[2,]
prop["PC1"] + prop["PC2"]
```

The first two principal components capture $3.4$% of the variance.
The number of principle components that we want to keep in order to explain the data depends on the percentage of the variance we want to explain, and the importance that we give on taking more components to explain a bigger part of the variance.
The script below computes the number of components we would keep to explain the data, using a function that computes the total variance explained by taking $i$ components, minus the percentage of components used to explain the data ($\frac{i}{494}$), $\forall i \in \{1, ..., 494\}$.

```{r}
res = rep(0, 494)
x=0
for (i in 1:494) {
  x = x + prop[i]
  res[i] = x - i/494
}

plot(c(1:494), res, type="l")
i = which(res == max(res))
i
```

Using this function, we would use $190$ principal components.

## Question 4

### a)

```{r}
latlongaxes=c(1:250)
lmlat <- lm(NAm2$lat~pcaNAm2$x[,latlongaxes])
lmlong <- lm(NAm2$long~pcaNAm2$x[,latlongaxes])
plot(lmlong$fitted.values,lmlat$fitted.values,col="white", asp=1)
for (i in 1:npop) {
  lines(lmlong$fitted.values[which(NAm2[,3]==names[i])],lmlat$fitted.values[which(NAm2[,3]==names[i])],type="p",col=colPalette[i],pch=pch[i]
  )
}
legend("bottomleft",legend=names,col=colPalette,lty=-1,pch=pch,cex=.75,ncol=2,lwd=2)
map("world",add=T)
```

Comparing with the first map, we can see that the population are well located and well centered around the expected position based on training data. But the map illustrate too optimistically the ability to locate people according to their genetic material. In fact we tested our model with the training data.

### b)

```{r}
m1 <- matrix(c(lmlong$fitted.values, lmlat$fitted.values), ncol = 2, byrow = FALSE)
m2 <- matrix(c(NAm2$long, NAm2$lat), ncol=2)
dist <- fields::rdist.earth(m1, m2, miles=FALSE)
mea <- mean(diag(dist))
mea
```

We can see that the population are predicted with a mean error of arround $476$km.

## Question 5

### a)
The cross validation method consists into dividing our data in a training set and a test set. The optimisation of the prediction method is made with the training set and its validity is mesured with the training set. It is possible to do it once or multiple times by dividing the data in different ways.
This method is interesting to build a predictive model because it allows you to test your model on data no used to train it. Indeed test your model with the training data is really thwart.

### b)


  